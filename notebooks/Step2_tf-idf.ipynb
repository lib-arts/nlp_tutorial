{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "参考リスト\n",
    "http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "-> scikit-learnの公式UserGuideの4.2.3、情報が豊富\n",
    "\"\"\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "# CountVectrizerクラス\n",
    "vectorizer = CountVectorizer()\n",
    "print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'int'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(\"saa\"))\n",
    "print(type(12))\n",
    "print((type([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 1)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 5)\t2\n",
      "  (2, 6)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 8)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 1)\t1\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# vectorizer.fit_transform\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# vectorizer.build_analyzer\n",
    "analyze = vectorizer.build_analyzer()\n",
    "print(analyze(\"This is a text document to analyze.\") == (\n",
    "    ['this', 'is', 'text', 'document', 'to', 'analyze']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# vectorizer.get_feature_names\n",
    "print(vectorizer.get_feature_names() == (\n",
    "    ['and', 'document', 'first', 'is', 'one',\n",
    "     'second', 'the', 'third', 'this']))\n",
    "\n",
    "print(type(X))\n",
    "print(type(X.toarray()))\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfTransformer(norm='l2', smooth_idf=False, sublinear_tf=False,\n",
      "         use_idf=True)\n"
     ]
    }
   ],
   "source": [
    "# TfidfTransformer class\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "print(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t0.5732079309279059\n",
      "  (0, 0)\t0.8194099510753754\n",
      "  (1, 0)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 1)\t0.8808994832762984\n",
      "  (4, 0)\t0.47330339145578754\n",
      "  (5, 2)\t0.8135516873095774\n",
      "  (5, 0)\t0.5814926070688599\n",
      "[[0.81940995 0.         0.57320793]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.47330339 0.88089948 0.        ]\n",
      " [0.58149261 0.         0.81355169]]\n"
     ]
    }
   ],
   "source": [
    "# transformer.fit_transform(tf-idf)\n",
    "counts = [[3, 0, 1],\n",
    "          [2, 0, 0],\n",
    "          [3, 0, 0],\n",
    "          [4, 0, 0],\n",
    "          [3, 2, 0],\n",
    "          [3, 0, 2]]\n",
    "\n",
    "tfidf = transformer.fit_transform(counts)\n",
    "print(tfidf)                         \n",
    "\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1 0 1]]\n",
      "  (0, 8)\t0.43306684852870914\n",
      "  (0, 6)\t0.33631504064053513\n",
      "  (0, 3)\t0.43306684852870914\n",
      "  (0, 2)\t0.5694308628404254\n",
      "  (0, 1)\t0.43306684852870914\n",
      "  (1, 8)\t0.24014568197368427\n",
      "  (1, 6)\t0.1864945448191575\n",
      "  (1, 5)\t0.8900617613631526\n",
      "  (1, 3)\t0.24014568197368427\n",
      "  (1, 1)\t0.24014568197368427\n",
      "  (2, 7)\t0.5611595317509138\n",
      "  (2, 6)\t0.23515939227529373\n",
      "  (2, 4)\t0.5611595317509138\n",
      "  (2, 0)\t0.5611595317509138\n",
      "  (3, 8)\t0.43306684852870914\n",
      "  (3, 6)\t0.33631504064053513\n",
      "  (3, 3)\t0.43306684852870914\n",
      "  (3, 2)\t0.5694308628404254\n",
      "  (3, 1)\t0.43306684852870914\n"
     ]
    }
   ],
   "source": [
    "tfidf = transformer.fit_transform(X.toarray())\n",
    "print(X.toarray())\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
