{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "参考リスト\n",
    "http://mocobeta.github.io/janome/\n",
    "-> Janomeの公式ドキュメント、用法が載っている\n",
    "https://github.com/mocobeta/janome\n",
    "-> Janomeのリポジトリ\n",
    "\"\"\"\n",
    "import codecs\n",
    "from janome.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すもも\n",
      "も\n",
      "もも\n",
      "も\n",
      "もも\n",
      "の\n",
      "うち\n"
     ]
    }
   ],
   "source": [
    "# 簡単な使用方法\n",
    "t = Tokenizer()\n",
    "for token in t.tokenize(u'すもももももももものうち'):\n",
    "    #print(token.part_of_speech)\n",
    "    print(token.surface)\n",
    "    #print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "東京スカイツリー\t名詞,固有名詞,一般,*,*,*,東京スカイツリー,トウキョウスカイツリー,トウキョウスカイツリー\n",
      "へ\t助詞,格助詞,一般,*,*,*,へ,ヘ,エ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "お越し\t名詞,一般,*,*,*,*,お越し,オコシ,オコシ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "東武スカイツリーライン\t名詞,固有名詞,一般,*,*,*,東武スカイツリーライン,トウブスカイツリーライン,トウブスカイツリーライン\n",
      "「\t記号,括弧開,*,*,*,*,「,「,「\n",
      "とうきょうスカイツリー駅\t名詞,固有名詞,一般,*,*,*,とうきょうスカイツリー駅,トウキョウスカイツリーエキ,トウキョウスカイツリーエキ\n",
      "」\t記号,括弧閉,*,*,*,*,」,」,」\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "便利\t名詞,形容動詞語幹,*,*,*,*,便利,ベンリ,ベンリ\n",
      "です\t助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n"
     ]
    }
   ],
   "source": [
    "# ユーザ辞書の導入\n",
    "t = Tokenizer(\"files_step1/userdic.csv\", udic_enc=\"utf8\")\n",
    "#t = Tokenizer()\n",
    "for token in t.tokenize(u'東京スカイツリーへのお越しは、東武スカイツリーライン「とうきょうスカイツリー駅」が便利です。'):\n",
    "    #print(token.part_of_speech)\n",
    "    #print(token.surface)\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下はAnalyzer（形態素解析の前処理・後処理をテンプレ化するためのフレームワーク）\n",
    "from janome.analyzer import Analyzer\n",
    "from janome.charfilter import *\n",
    "from janome.tokenfilter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "janome\t名詞,固有名詞,組織,*,*,*,janome,*,*\n",
      "pure\t名詞,固有名詞,組織,*,*,*,pure,*,*\n",
      "python\t名詞,一般,*,*,*,*,python,*,*\n",
      "な\t助動詞,*,*,*,特殊・ダ,体言接続,だ,ナ,ナ\n",
      "形態素解析器\t名詞,複合,*,*,*,*,形態素解析器,ケイタイソカイセキキ,ケイタイソカイセキキ\n",
      "です\t助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\n"
     ]
    }
   ],
   "source": [
    "# CharFilterを用いた前処理 や TokenFilterを用いた後処理\n",
    "text = u'蛇の目はPure Ｐｙｔｈｏｎな形態素解析器です。'\n",
    "char_filters = [UnicodeNormalizeCharFilter(), RegexReplaceCharFilter(u'蛇の目', u'janome')]\n",
    "tokenizer = Tokenizer()\n",
    "token_filters = [CompoundNounFilter(), POSStopFilter(['記号','助詞']), LowerCaseFilter()]\n",
    "a = Analyzer(char_filters, tokenizer, token_filters)\n",
    "for token in a.analyze(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すもも: 1\n",
      "もも: 2\n",
      "うち: 1\n"
     ]
    }
   ],
   "source": [
    "# TokenCountFilterを用いた入力文字列中の単語出現頻度のカウント\n",
    "text = u'すもももももももものうち'\n",
    "token_filters = [POSKeepFilter('名詞'), TokenCountFilter()]\n",
    "a = Analyzer(token_filters=token_filters)\n",
    "for k, v in a.analyze(text):\n",
    "    print('%s: %d' % (k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今回\t名詞,副詞可能,*,*,*,*,今回,コンカイ,コンカイ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "サンプル\t名詞,一般,*,*,*,*,サンプル,サンプル,サンプル\n",
      "な\t助動詞,*,*,*,特殊・ダ,体言接続,だ,ナ,ナ\n",
      "ので\t助詞,接続助詞,*,*,*,*,ので,ノデ,ノデ\n",
      "短く\t形容詞,自立,*,*,形容詞・アウオ段,連用テ接続,短い,ミジカク,ミジカク\n",
      "する\t動詞,自立,*,*,サ変・スル,基本形,する,スル,スル\n",
      "が\t助詞,接続助詞,*,*,*,*,が,ガ,ガ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "実際\t副詞,助詞類接続,*,*,*,*,実際,ジッサイ,ジッサイ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "大きな\t連体詞,*,*,*,*,*,大きな,オオキナ,オーキナ\n",
      "ファイル\t名詞,一般,*,*,*,*,ファイル,ファイル,ファイル\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "扱う\t動詞,自立,*,*,五段・ワ行促音便,基本形,扱う,アツカウ,アツカウ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n"
     ]
    }
   ],
   "source": [
    "# ストリーミングモード\n",
    "t = Tokenizer()\n",
    "with codecs.open('files_step1/very_large_text.txt', 'r', 'utf-8') as f:\n",
    "    txt = f.read()\n",
    "    for token in t.tokenize(txt, stream=True):\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['分かち書き', 'モード', 'が', 'つき', 'まし', 'た', '！']\n"
     ]
    }
   ],
   "source": [
    "# わかち書きモード\n",
    "t = Tokenizer()\n",
    "tokens = t.tokenize(u'分かち書きモードがつきました！', wakati=True)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
